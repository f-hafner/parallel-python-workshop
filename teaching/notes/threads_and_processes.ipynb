{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threads and processes\n",
    "\n",
    "An alternative option for parallelization is the built-in `threading` module in python. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads vs processes\n",
    "\n",
    "The difference between a thread and a task is that the thread shares the memory with the main process. A process is an independent instance of the python interpreter running with its own memory. \n",
    "- For example, if we have some (database) object in the main process, and we have two threads, then both threads have access to the same object \n",
    "- In contrast, if we have two processes, both objects exist independently in the two processes. This means that, when we start the processes, we need to send the objects to the two processes, and when they are done, we (possibly) need to transfer the data back to the parent process.\n",
    "\n",
    "\n",
    "**How does threading work?**\n",
    "- the main program `a.out` performs the main work and is the parent process. \n",
    "- it then creates a number of \"tasks\" (threads) that can be run concurrently \n",
    "- a thread can be best described as a \"subroutine\" within the main program; threads communicate with each other through the memory in the main process (global memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating from before\n",
    "import random \n",
    "\n",
    "def calc_pi(N, name=None):\n",
    "    \"Compute pi using N random samples\"\n",
    "    printing = name is not None\n",
    "    if printing:\n",
    "        print(f\"{name}: starting\")  \n",
    "    M = 0 \n",
    "    for i in range(N):\n",
    "        # Simulate random coordinates\n",
    "        x = random.uniform(-1, 1)\n",
    "        y = random.uniform(-1, 1)\n",
    "        if x**2 + y**2 < 1: # don't need sqrt b/c 1**2 = 1\n",
    "            M += 1\n",
    "\n",
    "    if printing:\n",
    "        print(f\"{name}: Done\")\n",
    "    return 4*M/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.71 s, sys: 0 ns, total: 5.71 s\n",
      "Wall time: 5.71 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.141774"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "calc_pi(10**7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 1: starting\n",
      "Thread 2: starting\n",
      "Thread 1: Done\n",
      "Thread 2: Done\n",
      "CPU times: user 6.28 s, sys: 18.8 ms, total: 6.3 s\n",
      "Wall time: 6.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "n=int((10**7)/2)\n",
    "t1 = Thread(target=calc_pi, args=(n, \"Thread 1\", ))\n",
    "t2 = Thread(target=calc_pi, args=(n, \"Thread 2\", ))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join() # http://docs.python.org/2/library/threading.html#threading.Thread.join\n",
    "# wait until the thread terminates. this will execute the work in the thread\n",
    "t2.join()\n",
    "\n",
    "# TODO: collect the result and show number of computations and compute pi? -- see examples later on?\n",
    "# https://stackoverflow.com/questions/6893968/how-to-get-the-return-value-from-a-thread\n",
    "# Is it correct that the point here is that this is run sequentially and there is no speedup?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: where is the speedup\n",
    "\n",
    "- ask in the group?\n",
    "\n",
    "**Solution**\n",
    "- Python only allows one thread to acces the interpreter at any given time. In other words, if we have a python session and start two threads, only one of them can execute python code at the time.\n",
    "- This means that the two threads are waiting for the other to finish their work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes from realpython\n",
    "\n",
    "- In python, a daemon thread shuts down immediately when a program exits. We can achieve this behavior when using `daemon=True` on the `threading.Thread` function. \n",
    "- If it is not specified, a thread is running in the background. It is only finished when `join` is called on it. Either this is done by us, or it is done when the program exits because python will close all objects, and on `threading` objects, the `_shutdown` method calls join under the hood.\n",
    "- If we call `join`, the main thread waits for the thread to finish. Whether `daemon=True` does not matter because the process is waited for to finish.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on the Global Interpreter Lock\n",
    "- The above did not run in parallel. The reason: python's global interpreter lock\n",
    "- It prevents us from using multiple cores from a single python instance.\n",
    "- This makes programming in python safer (to avoid race conditions?), but leads us to waste precious CPU resources.\n",
    "- We can circumvent or lift the GIL with two types of solutions \n",
    "    1. run multiple python instances: `multiprocessing`\n",
    "    2. have important code outside python: C++ extensions, cython, numba \n",
    "\n",
    "\n",
    "**Having multiple python instances**\n",
    "The problem is that we need to replicate program state between processes -- that is, if we load up a big dataset into memory and then run parallel processes on it, we need to transfer this big dataset to each child process. This is done with serialization (pickle, json) and creates large overhead. This is why multiprocessing should not be the first choice for parallelization.\n",
    "\n",
    "**Code outside python**\n",
    "Numpy has many routines that are situated outside of the GIL. Also numba makes this very easy, as we will show now.\n",
    "\n",
    "\n",
    "<mark>**Lesson learned: try out and profile your application!**</mark>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True, nogil=True)\n",
    "def calc_pi_nogil(N):\n",
    "    M = 0 \n",
    "    for i in range(N):\n",
    "        x = random.uniform(-1, 1)\n",
    "        y = random.uniform(-1, 1)\n",
    "        if x**2 + y**2 < 1:\n",
    "            M += 1 \n",
    "    return 4 * M / N \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.55 ms ± 191 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "time_nogil = %timeit -o calc_pi_nogil(10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566 ms ± 5.83 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "time_forloop = %timeit -o calc_pi(10**6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that numba makes it substantially faster, as already seen in previous section on numba/computing pi.\n",
    "\n",
    "**Note**\n",
    "\n",
    "In general, it is good practice to use `@numba.jit` with `noypython=True`, to make sure the code is run without running any python objects. There is also a more direct way to do this: `numba.njit`.\n",
    "If we use `nopython=True` and numba is not able to run the required code without any python, it will raise an error. If we do not specify `nopython=True`, it may fall back to object code (which is in python?), causing slowdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using nogil is 86.47 times faster than using the for loop\n"
     ]
    }
   ],
   "source": [
    "speedup = time_forloop.average / time_nogil.average\n",
    "print(f\"Using nogil is {speedup:.2f} times faster than using the for loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=False)\n",
    "def calc_pi_nogil_wrong(N):\n",
    "    M = 0 \n",
    "    for i in range(N):\n",
    "        x = random.uniform(-1, 1)\n",
    "        y = random.uniform(-1, 1)\n",
    "        if x**2 + y**2 < 1:\n",
    "            M += 1 \n",
    "    return 4 * M / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1164"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pi_nogil_wrong(10**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.54 ms ± 128 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "time_wrong = %timeit -o calc_pi_nogil_wrong(10**6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `time_wrong` and `time_nogil` take about the same time. Why is that?\n",
    "\n",
    "Note on numba options \n",
    "- `nogil` does not have any effect if we run it just like that above -- it's only when we start threading that we can see the speedup.\n",
    "    - This will be shown in the asyncio section; and in the next exercise.\n",
    "- `nopython=False` **still tries to compile to machine code**, but *does not require it*; but because the simple example above succeeds in compiling to use no python objects at all, we do not see a difference in speed when using `nopython=False` and `nopython=True`.\n",
    "\n",
    "-> the exercise below is kind of in this spirit: numpy always (?) releases the GIL. So I could make this more clear then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Exercise</mark>: Threading on a numpy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "a = np.random.random(10**6)\n",
    "b = np.random.random(10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 ms ± 767 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 10\n",
    "np.sort(a)\n",
    "np.sort(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.3 ms ± 1.39 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 10\n",
    "t1 = Thread(target=np.sort, args=(a, ))\n",
    "t2 = Thread(target=np.sort, args=(a, ))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "a1 = t1.join()\n",
    "a2 = t2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a speed-up of about 50%, which we get because we process the threads in parallel in numpy releases the GIL. \n",
    "The same we could achieve with numba (or with numpy) for the `calc_pi` function. Should we do this as an additional exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "\n",
    "We can run multiple processes in parallel with the `multiprocessing` module. Its API is similar to the one from threading, but its behavior is quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1: starting\n",
      "Process 2: starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1: Done\n",
      "Process 2: Done\n",
      "CPU times: user 7.01 ms, sys: 8.08 ms, total: 15.1 ms\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # n = 10**6\n",
    "    n=int((10**7)/2)\n",
    "    p1 = Process(target=calc_pi, args=(n, \"Process 1\"))\n",
    "    p2 = Process(target=calc_pi, args=(n, \"Process 2\"))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is going on?\n",
    "\n",
    "- In contrast to `threading` without releasing the GIL, we managed to get a speed up here of a bit less than 50 percent\n",
    "- **But**, under the hood, two new processes with a fresh copy of the python interpreter are created; and all resources associated to the parent are transferred\n",
    "- Creating a process is resource intensive, multiprocessing is only beneficial if running the function is larger than the overhead of creating a new process\n",
    "    - In the present context, this seems to be true since there are few objects to be transferred between processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `multiprocessing` safely\n",
    "\n",
    "- when we do multiprocessing, recall that a new python process is created with the same objects as the parent process \n",
    "- ie, we want to have the `calc_pi` function available, but we do not want to set up multiple processes *again* (in the child processes). To make sure this does not happen, we protect the parallelization part of the code inside the `if __name__ == \"__main__\"` statement. This will then not be executed by the child processes.\n",
    "- \"you need to code with the expectation that the calling module will be imported\"\n",
    "\n",
    "**Setting `mp.get_context`**\n",
    "- we can use `mp.get_context` to define the startup method \n",
    "    - they are \"fork\", \"spawn\" and \"forkserver\". \"spawn\" is the default on windows and mac, \"fork\" is the default (currently?) on linux \n",
    "- this gives us flexibility to change the start method even within a program if necessary. this may for instance be if we use third-party libraries that require different start methods\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1: starting\n",
      "Process 2: starting\n",
      "Process 1: Done\n",
      "Process 2: Done\n",
      "CPU times: user 4.71 ms, sys: 8.03 ms, total: 12.7 ms\n",
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # n = 10**6\n",
    "    n=int((10**7)/2)\n",
    "    ctx = mp.get_context(\"fork\") # spawn fill fail within the notebook \n",
    "    # with ctx as c:\n",
    "    p1 = ctx.Process(target=calc_pi, args=(n, \"Process 1\"))\n",
    "    p2 = ctx.Process(target=calc_pi, args=(n, \"Process 2\"))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1: starting\n",
      "Process 2: starting\n",
      "Process 1: Done\n",
      "Process 2: Done\n",
      "CPU times: user 46.4 ms, sys: 12 ms, total: 58.4 ms\n",
      "Wall time: 3.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "!python teaching/notes/pi_with_context.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipped for now: passing objects & sharing state; using contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "!python teaching/notes/mp_queue.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Exercise</mark> Overhead and the gains from multiprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "Make two python files\n",
    "\n",
    "To vary the amount of work: `mp_pool.py`\n",
    "\n",
    "```python\n",
    "\"Vary the amount of work\"\n",
    "\n",
    "\n",
    "from itertools import repeat\n",
    "import multiprocessing as mp\n",
    "from timeit import timeit\n",
    "from calc_pi import calc_pi\n",
    "\n",
    "\n",
    "def submit(ctx, N):\n",
    "    with ctx.Pool() as pool:\n",
    "        pool.starmap(calc_pi, repeat((N,), 4))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ctx = mp.get_context(\"spawn\")\n",
    "    for i in (100, 1_000, 10_000, 1_000_000, 10_000_000): # note true N is 4*this input, but same order of magnitude\n",
    "        res = timeit(lambda: submit(ctx, i), number=5)\n",
    "        print(f\"Using {i} samples took {res} seconds.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To vary the amount of workers: `mp_pool_vary_processes`\n",
    "\n",
    "```python\n",
    "\"Vary the amount of workers\"\n",
    "from itertools import repeat\n",
    "import multiprocessing as mp\n",
    "from timeit import timeit\n",
    "\n",
    "from calc_pi import calc_pi\n",
    "\n",
    "\n",
    "def submit(ctx, n_procs):\n",
    "    with ctx.Pool() as pool:\n",
    "        pool.starmap(calc_pi, repeat((1_000_000//n_procs,), n_procs))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ctx = mp.get_context(\"spawn\")\n",
    "    for i in (1, 2, 4, 8, 16): \n",
    "        res = timeit(lambda: submit(ctx, i), number=5)\n",
    "        print(f\"Using {i} workers took {res} seconds.\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 samples took 0.3531035240011988 seconds.\n",
      "Using 1000 samples took 0.29756459900090704 seconds.\n",
      "Using 10000 samples took 0.33205998300400097 seconds.\n",
      "Using 1000000 samples took 3.531531136999547 seconds.\n",
      "Using 10000000 samples took 39.767159585004265 seconds.\n"
     ]
    }
   ],
   "source": [
    "!python teaching/notes/mp_pool.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 workers took 3.020324115997937 seconds.\n",
      "Using 2 workers took 1.678884608001681 seconds.\n",
      "Using 4 workers took 1.104707567996229 seconds.\n",
      "Using 8 workers took 1.284393492001982 seconds.\n",
      "Using 16 workers took 1.2315388829956646 seconds.\n"
     ]
    }
   ],
   "source": [
    "!python teaching/notes/mp_pool_vary_processes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lessons learned \n",
    "\n",
    "**Varying the amount of work**\n",
    "- overhead from creating processes. fixed cost -> for low `N`, the overhead dominates, and we need high enough `N` to make this worthwhile.\n",
    "- We can back out the overhead from the very small `N`: it is about 0.3 seconds\n",
    "- with larger samples (`1_000_000` -> `10_000_000`), a 10x increase in the amount of work results in a more than 10x increase in the time taken.\n",
    "\n",
    "\n",
    "**Varying the number of processes**\n",
    "- If our task is large enough (`N = 1_000_000`), it makes sense to spread across multiple workers. We get a speed-up. \n",
    "    - Compare this to `N = 100`, where there is barely any speed-up as we increase the number of workers. This is because of the overhead from creating the python processes.\n",
    "- There are limits because of CPU congestion (only have 4 physical cores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77 ms, sys: 0 ns, total: 77 ms\n",
      "Wall time: 93.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.13896"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "calc_pi(100_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debriefing\n",
    "- add section on https://docs.python.org/3/library/concurrent.futures.html? (replace part of the old sections?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
